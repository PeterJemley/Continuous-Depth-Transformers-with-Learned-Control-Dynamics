{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN4Y4PwXcs6Ps7aOyYDK9UY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wf1tnG__xDr4","executionInfo":{"status":"ok","timestamp":1768436971703,"user_tz":480,"elapsed":4920,"user":{"displayName":"Peter Jemley MSHI","userId":"03334320751030864830"}},"outputId":"6bb534e1-bb2f-40e6-d05e-338dcd221e7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.12/dist-packages (0.2.5)\n","Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from torchdiffeq) (2.9.0+cu126)\n","Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from torchdiffeq) (1.16.3)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.5.0->torchdiffeq) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.3)\n","Running on: cuda\n","Model Parameters: 20471041\n","Starting Training (Fixed Euler Steps)...\n","Step 0 | Loss: 10.5640\n","Step 10 | Loss: 10.5746\n","Step 20 | Loss: 10.5987\n","Step 30 | Loss: 10.5581\n","Step 40 | Loss: 10.6220\n","Training finished in 2.02s\n","\n","--- RUNNING POPPERIAN CONTINUITY TEST ---\n","Fixed (4-step) vs Adaptive (Dopri5) Divergence: 0.0674%\n","PASS: Divergence < 10.0%. The model approximates a continuous vector field.\n","Verdict: The 'Continuous' claim is robust.\n"]}],"source":["# %% [markdown]\n","# # Continuous-Depth Transformers with Learned Control Dynamics\n","# ## Recreation & Falsification Experiments\n","#\n","# This notebook implements the hybrid ODE-Transformer architecture.\n","# It includes specific \"Popperian\" patches to verify:\n","# 1. The explicit injection mechanism of the control signal `u`.\n","# 2. The mathematical continuity of the learned dynamics (Fixed vs. Adaptive check).\n","\n","# %% [code]\n","# 1. INSTALL DEPENDENCIES\n","import sys\n","!{sys.executable} -m pip install torchdiffeq\n","\n","import math\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchdiffeq import odeint_adjoint as odeint\n","\n","# Configuration based on your paper (Section 4)\n","CONFIG = {\n","    'd_model': 256,\n","    'n_heads': 4,\n","    'n_layers': 6,          # Total effective layers\n","    'ode_layer_start': 2,   # Replace layers 2 & 3\n","    'ode_layer_end': 4,\n","    'vocab_size': 33278,    # WikiText-2 vocab size approx\n","    'seq_len': 32,\n","    'control_dim': 4,       # Low-dimensional control u\n","    'batch_size': 32,\n","    'lr': 0.001,\n","    'epochs': 1             # Short run for demonstration\n","}\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Running on: {DEVICE}\")\n","\n","# %% [markdown]\n","# ## 2. Architecture Definitions (With Popperian Patches)\n","\n","# %% [code]\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, d_model, n_heads, max_len=512):\n","        super().__init__()\n","        self.c_attn = nn.Linear(d_model, 3 * d_model)\n","        self.c_proj = nn.Linear(d_model, d_model)\n","        self.n_heads = n_heads\n","        self.d_model = d_model\n","        self.register_buffer(\"bias\", torch.tril(torch.ones(max_len, max_len))\n","                                     .view(1, 1, max_len, max_len))\n","\n","    def forward(self, x):\n","        B, T, C = x.size()\n","        q, k, v = self.c_attn(x).split(self.d_model, dim=2)\n","        k = k.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n","        q = q.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n","        v = v.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n","\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        y = att @ v\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        return self.c_proj(y)\n","\n","class MLP(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(d_model, 4 * d_model),\n","            nn.GELU(),\n","            nn.Linear(4 * d_model, d_model)\n","        )\n","    def forward(self, x): return self.net(x)\n","\n","class StandardBlock(nn.Module):\n","    def __init__(self, d_model, n_heads):\n","        super().__init__()\n","        self.ln1 = nn.LayerNorm(d_model)\n","        self.attn = CausalSelfAttention(d_model, n_heads)\n","        self.ln2 = nn.LayerNorm(d_model)\n","        self.mlp = MLP(d_model)\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.ln1(x))\n","        x = x + self.mlp(self.ln2(x))\n","        return x\n","\n","# --- THE PATCH: Explicit Control Injection ---\n","class ControlledVectorField(nn.Module):\n","    \"\"\"\n","    Explicitly defines F(h, t, u) = MLP(Concat(h, u)).\n","    This resolves the \"Black Box Injection\" ambiguity.\n","    \"\"\"\n","    def __init__(self, d_model, control_dim):\n","        super().__init__()\n","        # Explicit injection: Concatenate hidden state + control vector\n","        input_dim = d_model + control_dim\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, d_model * 2),\n","            nn.Softplus(), # Smooth activation for better ODE properties\n","            nn.Linear(d_model * 2, d_model)\n","        )\n","\n","        # Stability Initialization: Initialize output to near-zero\n","        # This keeps the initial vector field 'flat', aiding stability.\n","        nn.init.normal_(self.net[-1].weight, mean=0, std=0.01)\n","        nn.init.constant_(self.net[-1].bias, 0)\n","\n","    def forward(self, t, h, u):\n","        # h: [Batch, Seq, Dim]\n","        # u: [Batch, Control_Dim]\n","\n","        # Broadcast u across the sequence dimension\n","        seq_len = h.shape[1]\n","        u_expanded = u.unsqueeze(1).expand(-1, seq_len, -1)\n","\n","        # Concat and project\n","        state = torch.cat([h, u_expanded], dim=-1)\n","        return self.net(state)\n","\n","# --- THE PATCH: Hybrid Block with Fixed/Adaptive Toggle ---\n","class ContinuousDepthBlock(nn.Module):\n","    def __init__(self, d_model, control_dim):\n","        super().__init__()\n","        self.vector_field = ControlledVectorField(d_model, control_dim)\n","\n","        # Learned scale parameter initialized to 0.1 (Section 3.3)\n","        self.alpha = nn.Parameter(torch.tensor(0.1))\n","\n","        # Training defaults (Fixed Step)\n","        self.train_method = 'euler'\n","        self.train_options = {'step_size': 0.25} # 4 steps for t=[0,1]\n","\n","    def forward(self, h, u, use_adaptive=False):\n","        # Wrapper to bind 'u' so solver sees f(t, h)\n","        def func(t, x):\n","            return self.alpha * self.vector_field(t, x, u)\n","\n","        integration_times = torch.tensor([0, 1]).float().to(h.device)\n","\n","        # Switch between Fixed (Train) and Adaptive (Analysis)\n","        if use_adaptive:\n","            method = 'dopri5'\n","            options = {}\n","        else:\n","            method = self.train_method\n","            options = self.train_options\n","\n","        # ODESolve\n","        # Collect all parameters that `func` depends on\n","        adjoint_params = tuple(self.vector_field.parameters()) + (self.alpha,)\n","        state = odeint(func, h, integration_times, method=method, options=options, adjoint_params=adjoint_params)\n","        return state[1]\n","\n","class HybridTransformer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embed = nn.Embedding(config['vocab_size'], config['d_model'])\n","        self.pos_embed = nn.Parameter(torch.zeros(1, config['seq_len'], config['d_model']))\n","\n","        # 1. Discrete Early Layers (0-1)\n","        self.early_layers = nn.ModuleList([\n","            StandardBlock(config['d_model'], config['n_heads'])\n","            for _ in range(config['ode_layer_start'])\n","        ])\n","\n","        # 2. Continuous ODE Block (Replaces 2-3)\n","        self.ode_block = ContinuousDepthBlock(config['d_model'], config['control_dim'])\n","\n","        # 3. Discrete Late Layers (4-5)\n","        # Note: We subtract the layers we 'skipped' to keep indices aligned\n","        remaining_layers = config['n_layers'] - config['ode_layer_end']\n","        self.late_layers = nn.ModuleList([\n","            StandardBlock(config['d_model'], config['n_heads'])\n","            for _ in range(remaining_layers)\n","        ])\n","\n","        self.ln_f = nn.LayerNorm(config['d_model'])\n","        self.head = nn.Linear(config['d_model'], config['vocab_size'], bias=False)\n","\n","    def forward(self, idx, u, use_adaptive=False):\n","        B, T = idx.size()\n","        x = self.embed(idx) + self.pos_embed[:, :T, :]\n","\n","        # Early Discrete\n","        for layer in self.early_layers:\n","            x = layer(x)\n","\n","        # Continuous Control\n","        x = self.ode_block(x, u, use_adaptive=use_adaptive)\n","\n","        # Late Discrete\n","        for layer in self.late_layers:\n","            x = layer(x)\n","\n","        logits = self.head(self.ln_f(x))\n","        return logits\n","\n","# %% [markdown]\n","# ## 3. Data & Training Setup\n","\n","# %% [code]\n","# Dummy Data Generator (Replacing WikiText download for instant runnability)\n","# In real exp, replace this with 'datasets' load\n","def get_batch(config):\n","    data = torch.randint(0, config['vocab_size'], (config['batch_size'], config['seq_len'] + 1)).to(DEVICE)\n","    x = data[:, :-1]\n","    y = data[:, 1:]\n","\n","    # Random control signal for training\n","    # We want the model to learn to be robust to ANY u\n","    u = torch.randn(config['batch_size'], config['control_dim']).to(DEVICE)\n","    return x, y, u\n","\n","model = HybridTransformer(CONFIG).to(DEVICE)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n","\n","print(f\"Model Parameters: {sum(p.numel() for p in model.parameters())}\")\n","print(\"Starting Training (Fixed Euler Steps)...\")\n","\n","# Simple Training Loop\n","model.train()\n","start_time = time.time()\n","\n","for step in range(50): # Small steps for demo\n","    x, y, u = get_batch(CONFIG)\n","\n","    # Forward pass (Fixed Steps)\n","    logits = model(x, u, use_adaptive=False)\n","\n","    # Fix: Use .reshape() instead of .view() for non-contiguous tensors\n","    loss = F.cross_entropy(logits.reshape(-1, CONFIG['vocab_size']), y.reshape(-1))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Gradient clipping (standard for transformers)\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    optimizer.step()\n","\n","    if step % 10 == 0:\n","        print(f\"Step {step} | Loss: {loss.item():.4f}\")\n","\n","print(f\"Training finished in {time.time() - start_time:.2f}s\")\n","\n","# %% [markdown]\n","# ## 4. The Popperian Falsification Test\n","#\n","# We now test if the model is a \"ResNet in disguise\" (failed hypothesis) or a \"Continuous Flow\" (confirmed hypothesis).\n","# We compare the output of the **Fixed 4-Step Solver** (used in training) vs. an **Adaptive Dopri5 Solver**.\n","\n","# %% [code]\n","def validate_continuity_hypothesis(model, config):\n","    print(\"\\n--- RUNNING POPPERIAN CONTINUITY TEST ---\")\n","    model.eval()\n","\n","    # Get a probe batch\n","    x, _, u = get_batch(config)\n","\n","    with torch.no_grad():\n","        # 1. Run Fixed Step (What it learned)\n","        logits_fixed = model(x, u, use_adaptive=False)\n","\n","        # 2. Run Adaptive Step (The theoretical limit)\n","        # If the dynamics are smooth/continuous, this should yield a very similar result.\n","        # If the dynamics are discrete/overfit, this will diverge.\n","        logits_adaptive = model(x, u, use_adaptive=True)\n","\n","        # Measure divergence in the hidden space (before readout)\n","        # We access the block output directly for cleaner measurement\n","        # Re-running just the block flow:\n","        emb = model.embed(x) + model.pos_embed[:, :config['seq_len'], :]\n","        for l in model.early_layers: emb = l(emb)\n","\n","        h_fixed = model.ode_block(emb, u, use_adaptive=False)\n","        h_adaptive = model.ode_block(emb, u, use_adaptive=True)\n","\n","        # Relative Error\n","        diff = (h_fixed - h_adaptive).norm()\n","        base = h_adaptive.norm()\n","        rel_error = (diff / base).item()\n","\n","    print(f\"Fixed (4-step) vs Adaptive (Dopri5) Divergence: {rel_error:.4%}\")\n","\n","    threshold = 0.10 # 10% tolerance\n","    if rel_error < threshold:\n","        print(f\"PASS: Divergence < {threshold*100}%. The model approximates a continuous vector field.\")\n","        print(\"Verdict: The 'Continuous' claim is robust.\")\n","    else:\n","        print(f\"FAIL: Divergence > {threshold*100}%. The model is effectively a discrete ResNet.\")\n","        print(\"Verdict: The 'Continuous' claim is falsified. Needs 'Consistency Loss' in training.\")\n","\n","# Run the test\n","validate_continuity_hypothesis(model, CONFIG)"]},{"cell_type":"code","source":["# Check the learned output scale\n","final_alpha = model.ode_block.alpha.item()\n","print(f\"Final learned alpha: {final_alpha:.6f}\")\n","\n","# Interpretation logic\n","if final_alpha < 0.05:\n","    print(\"Result: The model suppressed the dynamics (closer to Identity).\")\n","elif final_alpha > 0.15:\n","    print(\"Result: The model amplified the dynamics (needed more 'time').\")\n","else:\n","    print(\"Result: The model maintained the stable regime (close to initialization).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XAMy9CJAzJ-","executionInfo":{"status":"ok","timestamp":1768436971710,"user_tz":480,"elapsed":3,"user":{"displayName":"Peter Jemley MSHI","userId":"03334320751030864830"}},"outputId":"f2d2957e-2bf4-48ab-b1ef-d5e5aae1c4c4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Final learned alpha: 0.068112\n","Result: The model maintained the stable regime (close to initialization).\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","def probe_decision_dynamics(model, config):\n","    print(\"--- Probing Representation Dynamics ---\")\n","    # Get a batch of data with mixed sentiment targets\n","    x, y, u = get_batch(config) # u should be mixed +1/-1\n","\n","    # We need to extract states at specific depths.\n","    # We'll use the adaptive solver to record the trajectory.\n","    times = torch.tensor([0, 0.5, 0.67, 0.8, 1.0]).float().to(DEVICE)\n","\n","    with torch.no_grad():\n","        # 1. Embed and Early Layers\n","        emb = model.embed(x) + model.pos_embed[:, :config['seq_len'], :]\n","        for l in model.early_layers: emb = l(emb)\n","\n","        # 2. Run ODE Solver explicitly asking for evaluation at specific times\n","        # Note: We need to modify the forward pass slightly or just call odeint directly here\n","        def func(t, h): return model.ode_block.alpha * model.ode_block.vector_field(t, h, u)\n","\n","        # Explicitly define adjoint_params for func\n","        adjoint_params = tuple(model.ode_block.vector_field.parameters()) + (model.ode_block.alpha,)\n","\n","        # trajectory shape: [Times, Batch, Seq, Dim]\n","        trajectory = odeint(func, emb, times, method='dopri5', adjoint_params=adjoint_params)\n","\n","    # Train a simple classifier at each depth\n","    # Target: 1 if u > 0 (Positive), 0 if u < 0 (Negative)\n","    targets = (u[:, 0] > 0).cpu().numpy().astype(int)\n","\n","    results = {}\n","    for i, t_val in enumerate(times):\n","        # Pool output (e.g., mean over sequence) for classification\n","        states = trajectory[i].mean(dim=1).cpu().numpy()\n","\n","        # Simple Logic: Train on half, test on half\n","        split = len(states) // 2\n","        clf = LogisticRegression(max_iter=1000).fit(states[:split], targets[:split])\n","        acc = clf.score(states[split:], targets[split:])\n","\n","        print(f\"Depth {t_val:.2f}: Linear Separation Accuracy = {acc:.1%}\")\n","        results[t_val.item()] = acc\n","\n","# Run it\n","probe_decision_dynamics(model, CONFIG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3jaIkseCTuB","executionInfo":{"status":"ok","timestamp":1768436971961,"user_tz":480,"elapsed":252,"user":{"displayName":"Peter Jemley MSHI","userId":"03334320751030864830"}},"outputId":"3c1a3e59-deb9-4d73-9de4-55da49362180"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Probing Representation Dynamics ---\n","Depth 0.00: Linear Separation Accuracy = 62.5%\n","Depth 0.50: Linear Separation Accuracy = 62.5%\n","Depth 0.67: Linear Separation Accuracy = 62.5%\n","Depth 0.80: Linear Separation Accuracy = 62.5%\n","Depth 1.00: Linear Separation Accuracy = 62.5%\n"]}]}]}